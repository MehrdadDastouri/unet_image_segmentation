{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3bXF3pYfZ5VHpAGgnyVWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadDastouri/unet_image_segmentation/blob/main/unet_image_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# U-Net model definition\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1):\n",
        "        super(UNet, self).__init__()\n",
        "        # Encoder\n",
        "        self.conv1 = self.double_conv(in_channels, 64)\n",
        "        self.conv2 = self.double_conv(64, 128)\n",
        "        self.conv3 = self.double_conv(128, 256)\n",
        "        self.conv4 = self.double_conv(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.double_conv(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv4 = self.upconv(1024, 512)\n",
        "        self.dec4 = self.double_conv(1024, 512)\n",
        "        self.upconv3 = self.upconv(512, 256)\n",
        "        self.dec3 = self.double_conv(512, 256)\n",
        "        self.upconv2 = self.upconv(256, 128)\n",
        "        self.dec2 = self.double_conv(256, 128)\n",
        "        self.upconv1 = self.upconv(128, 64)\n",
        "        self.dec1 = self.double_conv(128, 64)\n",
        "\n",
        "        # Final layer\n",
        "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def double_conv(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def upconv(self, in_channels, out_channels):\n",
        "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        c1 = self.conv1(x)\n",
        "        p1 = nn.MaxPool2d(2)(c1)\n",
        "        c2 = self.conv2(p1)\n",
        "        p2 = nn.MaxPool2d(2)(c2)\n",
        "        c3 = self.conv3(p2)\n",
        "        p3 = nn.MaxPool2d(2)(c3)\n",
        "        c4 = self.conv4(p3)\n",
        "        p4 = nn.MaxPool2d(2)(c4)\n",
        "\n",
        "        # Bottleneck\n",
        "        bn = self.bottleneck(p4)\n",
        "\n",
        "        # Decoder\n",
        "        u4 = self.upconv4(bn)\n",
        "        d4 = self.dec4(torch.cat([u4, c4], dim=1))\n",
        "        u3 = self.upconv3(d4)\n",
        "        d3 = self.dec3(torch.cat([u3, c3], dim=1))\n",
        "        u2 = self.upconv2(d3)\n",
        "        d2 = self.dec2(torch.cat([u2, c2], dim=1))\n",
        "        u1 = self.upconv1(d2)\n",
        "        d1 = self.dec1(torch.cat([u1, c1], dim=1))\n",
        "\n",
        "        return self.final(d1)\n",
        "\n",
        "# Dataset class for image segmentation\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
        "        image = np.array(Image.open(img_path).convert(\"L\"))  # Convert to grayscale\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"))  # Convert to grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented[\"image\"]\n",
        "            mask = augmented[\"mask\"]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "class Transform:\n",
        "    def __call__(self, image, mask):\n",
        "        # Resize\n",
        "        image = TF.resize(image, (128, 128))\n",
        "        mask = TF.resize(mask, (128, 128))\n",
        "\n",
        "        # Convert to tensor\n",
        "        image = TF.to_tensor(image)\n",
        "        mask = TF.to_tensor(mask)\n",
        "\n",
        "        return {\"image\": image, \"mask\": mask}\n",
        "\n",
        "# Define dataset and data loaders\n",
        "train_transform = Transform()\n",
        "train_dataset = SegmentationDataset(\"data/images\", \"data/masks\", transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Initialize the model\n",
        "model = UNet(in_channels=1, out_channels=1).to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, masks in train_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Visualize a sample result\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_image, sample_mask = train_dataset[0]\n",
        "    sample_image = sample_image.unsqueeze(0).to(device)\n",
        "    predicted_mask = torch.sigmoid(model(sample_image))\n",
        "    predicted_mask = (predicted_mask > 0.5).float()\n",
        "\n",
        "# Plot original image, ground truth mask, and predicted mask\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(sample_image.cpu().squeeze(), cmap=\"gray\")\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Ground Truth Mask\")\n",
        "plt.imshow(sample_mask.cpu().squeeze(), cmap=\"gray\")\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Predicted Mask\")\n",
        "plt.imshow(predicted_mask.cpu().squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HucLV4dhKkcC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}